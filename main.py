import requests
import json
import os
from datetime import datetime
import urllib3

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Hacker News API åŸºç¡€ URL
BASE_URL = "https://hacker-news.firebaseio.com/v0"

def fetch_top_stories(limit=30):
    """è·å–çƒ­é—¨æ•…äº‹çš„ ID åˆ—è¡¨"""
    url = f"{BASE_URL}/topstories.json"
    response = requests.get(url, verify=False, timeout=10)
    story_ids = response.json()
    return story_ids[:limit]

def fetch_story_detail(story_id):
    """è·å–å•ä¸ªæ•…äº‹çš„è¯¦ç»†ä¿¡æ¯"""
    url = f"{BASE_URL}/item/{story_id}.json"
    try:
        response = requests.get(url, verify=False, timeout=10)
        return response.json()
    except Exception as e:
        print(f"  âš ï¸  è·å–æ•…äº‹ {story_id} å¤±è´¥: {str(e)[:50]}")
        return None

def filter_ai_stories(stories):
    """ç­›é€‰å‡º AI ç›¸å…³çš„æ•…äº‹"""
    ai_keywords = ['ai', 'artificial intelligence', 'machine learning',
                   'ml', 'deep learning', 'llm', 'gpt', 'openai',
                   'claude', 'chatgpt', 'neural']

    ai_stories = []
    for story in stories:
        title = story.get('title', '').lower()
        if any(keyword in title for keyword in ai_keywords):
            ai_stories.append(story)

    return ai_stories

def save_to_json(data, filename):
    """ä¿å­˜æ•°æ®åˆ° JSON æ–‡ä»¶"""
    os.makedirs('data', exist_ok=True)
    filepath = os.path.join('data', filename)

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ° {filepath}")

def main():
    print("ğŸš€ å¼€å§‹çˆ¬å– Hacker News AI ç›¸å…³çƒ­é—¨æ•…äº‹...")

    # 1. è·å–çƒ­é—¨æ•…äº‹ ID
    story_ids = fetch_top_stories(limit=30)
    print(f"ğŸ“Š è·å–åˆ° {len(story_ids)} ä¸ªçƒ­é—¨æ•…äº‹ ID")

    # 2. è·å–æ¯ä¸ªæ•…äº‹çš„è¯¦æƒ…
    stories = []
    for i, story_id in enumerate(story_ids, 1):
        print(f"â³ æ­£åœ¨è·å–ç¬¬ {i}/{len(story_ids)} ä¸ªæ•…äº‹...")
        story = fetch_story_detail(story_id)
        if story and story.get('type') == 'story':
            stories.append({
                'title': story.get('title'),
                'url': story.get('url'),
                'score': story.get('score'),
                'by': story.get('by'),
                'time': story.get('time'),
                'descendants': story.get('descendants', 0),  # è¯„è®ºæ•°
                'hn_url': f"https://news.ycombinator.com/item?id={story_id}"
            })

    print(f"âœ… æˆåŠŸè·å– {len(stories)} ä¸ªæ•…äº‹è¯¦æƒ…")

    # 3. ç­›é€‰ AI ç›¸å…³æ•…äº‹
    ai_stories = filter_ai_stories(stories)
    print(f"ğŸ¤– ç­›é€‰å‡º {len(ai_stories)} ä¸ª AI ç›¸å…³æ•…äº‹")

    # 4. ä¿å­˜æ•°æ®
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_to_json(ai_stories, f'hn_ai_stories_{timestamp}.json')

    # 5. æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
    print("\nğŸ“° éƒ¨åˆ† AI ç›¸å…³æ•…äº‹ï¼š")
    for story in ai_stories[:5]:
        print(f"  â€¢ {story['title']} (ğŸ‘ {story['score']})")

if __name__ == '__main__':
    main()
